{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import dxchange\n",
    "import nibabel as nib\n",
    "import tifffile\n",
    "from skimage.filters import threshold_otsu\n",
    "import localthickness as lt\n",
    "import json\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "os.chdir('/dtu/3d-imaging-center/courses/02509/groups/members/s194333/HPC3D_project')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/dtu/3d-imaging-center/courses/02509/groups/group01/statistics/'\n",
    "\n",
    "# Load the data frame\n",
    "df = pd.read_csv(os.path.join(folder_path, 'statistics_sample_3.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ratio  mean_thickness_stone  mean_thickness_bubbles  \\\n",
      "0  0.756010              1.957572                0.769248   \n",
      "1  0.808469              1.042226                0.649100   \n",
      "2  0.439130              0.989864                1.000067   \n",
      "3  0.538265              0.903176                0.830195   \n",
      "4  0.773654              0.845630                0.637488   \n",
      "\n",
      "   median_thickness_stone  median_thickness_bubbles  max_thickness_stone  \\\n",
      "0                2.207705                  0.757391             2.660572   \n",
      "1                1.064715                  0.682785             1.423666   \n",
      "2                0.750473                  1.079865             1.977087   \n",
      "3                0.856279                  0.870300             1.607189   \n",
      "4                0.784894                  0.738777             1.504338   \n",
      "\n",
      "   max_thickness_bubbles  var_thickness_stone  var_thickness_bubbles label  \n",
      "0               1.309358             0.576693               0.061252    ny  \n",
      "1               1.076190             0.091253               0.071255    ny  \n",
      "2               1.688119             0.382384               0.102654    ny  \n",
      "3               1.215817             0.195143               0.053195    ny  \n",
      "4               0.890192             0.079890               0.051163    ny  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127, 3) (32, 3) (127,) (32,)\n",
      "label\n",
      "ma    43\n",
      "gl    42\n",
      "ny    42\n",
      "Name: count, dtype: int64\n",
      "label\n",
      "gl    11\n",
      "ny    11\n",
      "ma    10\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# do logisic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Define the features and the target\n",
    "X = df[['ratio', 'mean_thickness_stone', 'mean_thickness_bubbles']]\n",
    "y = df['label']\n",
    "\n",
    "# Split the data into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# how many of each class\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Normalize the data\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the model\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "# Predict the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
